# Cube Localization using U-Net Autoencoders from Synthetic Sensor Data

This repository contains the code, trained models, and results for a project focused on localizing a cube within a defined area using synthetic acceleration sensor data processed into spectrograms and fed into U-Net based autoencoder architectures.

*Code formatting and documentation assistance provided by an AI language model (gemini-2.5-pro-exp-03-25).*

## Project Overview

The primary goal of this project is to predict the 2D position (represented as a binary mask) of a cube based on the input from four simulated acceleration sensors placed at the corners of a bounding box.

1.  **Synthetic Data Generation:** A dataset (`cube_dataset_500_examples`) is synthetically generated. For various cube positions, unique acceleration time-series signals are created for each sensor, incorporating position-dependent characteristics (frequency, amplitude, noise, transients, delays).
2.  **Spectrogram Conversion:** These time-series signals are converted into spectrograms (128x128 images), capturing the time-frequency information.
3.  **Model Training:** Two deep learning models based on autoencoder architectures are trained:
    *   `UNetAutoencoder`: A standard U-Net architecture.
    *   `UNetPPAutoencoder`: A U-Net++ architecture with nested and dense skip pathways.
    These models take the four spectrograms as input (4 channels) and output a predicted localization mask (64x64 image).
4.  **Evaluation:** Models are evaluated using Mean Squared Error (MSE) loss and visualized predictions against ground truth masks.

## Repository Structure

```
.
├── weights/                  # Saved trained model state dictionaries (*.pth)
├── results_dicts/            # Saved training results (loss history) (*.pkl)
├── interdisp_proj.ipynb      # Main Jupyter notebook with code for data generation, training, evaluation
├── README.md                 # This file
└── LICENSE                   # Project license (e.g., MIT License)
```

*(Note: The `cube_dataset_500_examples` directory is generated by running the notebook. The `weights` directory is an alternative save format often preferred over saving the entire model.)*

## Models & Results

The repository includes the following saved models and results (generated by the notebook):

*   **Weights (Results Dictionary):** Located in the `weights/` directory.
    *   `UNetAutoencoder_state_dict.pth`: Weights of standard U-Net model.
    *   `UNetPPAutoencoder_state_dict.pth`: Weights of trained U-Net++ model.
*   **Results (Loss History):** Located in the `results_dicts/` directory.
    *   `UNetAutoencoder_results.pkl`: Pickle file containing training/testing loss history for the U-Net model.
    *   `UNetPPAutoencoder_results.pkl`: Pickle file containing training/testing loss history for the U-Net++ model.

## Dependencies

Key libraries used in this project include:

*   Python 3.x
*   PyTorch
*   Torchvision
*   NumPy
*   Matplotlib
*   OpenCV-Python (`cv2`)
*   SciPy
*   Pillow (`PIL`)
*   torchinfo
*   Jupyter Notebook / Lab (for running `.ipynb`)

You can typically install these using pip or conda (refer to specific library documentation for details). Example using pip:
```bash
pip install torch torchvision numpy matplotlib opencv-python scipy Pillow torchinfo notebook
```

## Usage

1.  **Clone the Repository:**
    ```bash
    git clone https://github.com/podlen/interdisciplinarni_projekt.git
    cd interdisciplinarni_projekt
    ```
2.  **Set up Environment:** Ensure you have Python and the required dependencies installed.
3.  **Run the Notebook:** Open and execute the cells in `interdisp_proj.ipynb` using Jupyter Notebook or Jupyter Lab.
    *   The notebook first generates the synthetic dataset (`cube_dataset_500_examples`).
    *   It then defines the dataset loaders and model architectures.
    *   Finally, it trains the models, saves them (`models/`, `results_dicts/`), and visualizes the results.
4.  **Loading Pre-trained Models:** The notebook also includes cells demonstrating how to load the saved models (`.pth` files) and results dictionaries (`.pkl` files) for further analysis or inference.

## Citation

If you use this code or data in your research, please cite:

```bibtex
@software{podlipnik_cube_localization_2024,
  author = {Podlipnik, Enej},
  title = {{Cube Localization using U-Net Autoencoders from Synthetic Sensor Data}},
  year = {2025},
  publisher = {GitHub},
  url = {https://github.com/podlen/interdisciplinarni_projekt.git}
}
```

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Contact

Enej Podlipnik
Faculty of Mechanical Engineering (Fakulteta za strojništvo)
University of Ljubljana (Univerza v Ljubljani)
